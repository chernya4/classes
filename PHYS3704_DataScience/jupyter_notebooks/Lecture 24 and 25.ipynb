{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline   \n",
    "                     # this sets up matplotlib to make plots show up in the notebook\n",
    "import numpy as np   # imports the numpy package, abbreviated as np\n",
    "import matplotlib    # imports the matplotlib package for making plots\n",
    "import matplotlib.pyplot as plt    # imports the part of matplotlib we use most,\n",
    " \n",
    "\n",
    "import scipy.stats as stats\n",
    "import astropy.stats as astats\n",
    "import numpy.random as random\n",
    "from astropy.table import Table\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting for the Hubble constant with supernovae\n",
    "\n",
    "We are continuing to work with the Hicken et al. (\"Consitution\") supernova dataset.  First, we read in the file into a table named `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THE BELOW LINE TO POINT TO THE DIRECTORY CONTAINING SNDATA.TXT\n",
    "path = './'  \n",
    "\n",
    "# the astropy way\n",
    "#data=Table.read(path+'sndata.txt',format='ascii')\n",
    "\n",
    "# the pandas way: the file is in \"fixed-width format\" so we use read_fwf\n",
    "data=pd.read_fwf(path+'sndata.txt')\n",
    "\n",
    "cz=data['cz']\n",
    "mu=data['mu']\n",
    "sigma_mu=data['sigma_mu']\n",
    "weight=1/sigma_mu**2\n",
    "d = 10**(mu/5)*1E-5\n",
    "\n",
    "logv=np.log10(cz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with errors in the independent variable\n",
    "\n",
    "We can use `scipy.odr` for this case.\n",
    "\n",
    "__Note that you need to change__ \n",
    "\n",
    "`if 0` __to__ \n",
    "\n",
    "`if 1` __to get code to execute!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: [ 5.07700373 15.68526483]\n",
      "Beta Std Error: [0.0703514  0.28060092]\n",
      "Beta Covariance: [[ 0.00772955 -0.03079311]\n",
      " [-0.03079311  0.12296652]]\n",
      "Residual Variance: 0.6403114801421016\n",
      "Inverse Condition #: 0.009872856052889862\n",
      "Reason(s) for Halting:\n",
      "  Sum of squares convergence\n",
      "\n",
      "slope: 5.077 +/- 0.088\n",
      "intercept: 15.685 +/- 0.351\n",
      "H0: 72.94 km/sec/Mpc +/- 11.83\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.odr as odr\n",
    "\n",
    "# scipy odr package does nonlinear fitting with odr\n",
    "# see https://docs.scipy.org/doc/scipy/reference/odr.html\n",
    "\n",
    "\n",
    "# error due to peculiar velocities\n",
    "logverr=300./(cz)/np.log(10.)\n",
    "\n",
    "# define a linear function for the fit.  \n",
    "# Note: scipy.optimize.curve_fit would similarly require us\n",
    "#     to define a function whose parameters would be fit.\n",
    "f = lambda beta,x: beta[0]*x+beta[1]\n",
    "\n",
    "# define the model to fit\n",
    "linear = odr.Model(f)\n",
    "# define the dataset to be fit and the errors in each axis\n",
    "mydata = odr.RealData(logv, mu, sx=logverr, sy=sigma_mu)\n",
    "\n",
    "# set up the fit, including initial guesses for the parameters\n",
    "myodr = odr.ODR(mydata, linear, beta0=[5., 15.])\n",
    "# do the fit\n",
    "myoutput = myodr.run()\n",
    "# look at the results\n",
    "myoutput.pprint()\n",
    "slope=(myoutput.beta)[0]\n",
    "intercept=(myoutput.beta)[1]\n",
    "covar=myoutput.cov_beta\n",
    "print()\n",
    "\n",
    "if 1:   \n",
    "    h0err = (10**(-0.2*(intercept-np.sqrt(covar[1,1]) )-np.log10(1E-5) )\n",
    "              -10**(-0.2*(intercept+np.sqrt(covar[1,1]) )-np.log10(1E-5) ) ) /2.\n",
    "    \n",
    "    print(f'slope: {slope:.3f} +/- {np.sqrt(covar[0,0]):.3f}')\n",
    "    print(f'intercept: {intercept:.3f} +/- {np.sqrt(covar[1,1]):.3f}')\n",
    "    print(f'H0: {(10**(-0.2*intercept-np.log10(1E-5))):.2f} km/sec/Mpc +/- {h0err:.2f}')\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.errorbar(logv,mu,xerr=logverr,yerr=sigma_mu,fmt='b.',alpha=0.2)\n",
    "    plt.ylim(33,39)\n",
    "    plt.xlabel('log v')\n",
    "    plt.ylabel(r'$\\mu$')\n",
    "    plt.plot(logv,logv*slope+intercept,'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust regression\n",
    "\n",
    "We can use `statsmodels` for robust regression.  Note for interpreting documentation: the 'endogenous' variable is the _dependent_ one we are fitting for, 'exogenous' variables are the _independent_ ones whose values are just provided.\n",
    "First, we'll do a known case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With weights: 5.0483 15.7979\n",
      "No weights: 5.0577 15.7648\n"
     ]
    }
   ],
   "source": [
    "#The numpy way\n",
    "coeffs = np.polyfit(logv,mu,1,w=weight)\n",
    "print(f'With weights: {coeffs[0]:.4f} {coeffs[1]:.4f}')\n",
    "coeffs = np.polyfit(logv,mu,1)\n",
    "print(f'No weights: {coeffs[0]:.4f} {coeffs[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Take a look at the documentation for sm.WLS using the below code box.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WLS in module statsmodels.regression.linear_model:\n",
      "\n",
      "class WLS(RegressionModel)\n",
      " |  WLS(endog, exog, weights=1.0, missing='none', hasconst=None, **kwargs)\n",
      " |\n",
      " |  Weighted Least Squares\n",
      " |\n",
      " |  The weights are presumed to be (proportional to) the inverse of\n",
      " |  the variance of the observations.  That is, if the variables are\n",
      " |  to be transformed by 1/sqrt(W) you must supply weights = 1/W.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array_like\n",
      " |      A 1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array_like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  weights : array_like, optional\n",
      " |      A 1d array of weights.  If you supply 1/W then the variables are\n",
      " |      pre- multiplied by 1/sqrt(W).  If no weights are supplied the\n",
      " |      default value is 1 and WLS results are the same as OLS.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none'.\n",
      " |  hasconst : None or bool\n",
      " |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      " |      a constant is not checked for and k_constant is set to 1 and all\n",
      " |      result statistics are calculated as if a constant is present. If\n",
      " |      False, a constant is not checked for and k_constant is set to 0.\n",
      " |  **kwargs\n",
      " |      Extra arguments that are used to set model properties when using the\n",
      " |      formula interface.\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  weights : ndarray\n",
      " |      The stored weights supplied as an argument.\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  GLS : Fit a linear model using Generalized Least Squares.\n",
      " |  OLS : Fit a linear model using Ordinary Least Squares.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  If the weights are a function of the data, then the post estimation\n",
      " |  statistics such as fvalue and mse_model might not be correct, as the\n",
      " |  package does not yet support no-constant regression.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import statsmodels.api as sm\n",
      " |  >>> Y = [1,3,4,5,2,3,4]\n",
      " |  >>> X = range(1,8)\n",
      " |  >>> X = sm.add_constant(X)\n",
      " |  >>> wls_model = sm.WLS(Y,X, weights=list(range(1,8)))\n",
      " |  >>> results = wls_model.fit()\n",
      " |  >>> results.params\n",
      " |  array([ 2.91666667,  0.0952381 ])\n",
      " |  >>> results.tvalues\n",
      " |  array([ 2.0652652 ,  0.35684428])\n",
      " |  >>> print(results.t_test([1, 0]))\n",
      " |  <T test: effect=array([ 2.91666667]), sd=array([[ 1.41224801]]),\n",
      " |   t=array([[ 2.0652652]]), p=array([[ 0.04690139]]), df_denom=5>\n",
      " |  >>> print(results.f_test([0, 1]))\n",
      " |  <F test: F=array([[ 0.12733784]]), p=[[ 0.73577409]], df_denom=5, df_num=1>\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      WLS\n",
      " |      RegressionModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(\n",
      " |      self,\n",
      " |      endog,\n",
      " |      exog,\n",
      " |      weights=1.0,\n",
      " |      missing='none',\n",
      " |      hasconst=None,\n",
      " |      **kwargs\n",
      " |  )\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  fit_regularized(\n",
      " |      self,\n",
      " |      method='elastic_net',\n",
      " |      alpha=0.0,\n",
      " |      L1_wt=1.0,\n",
      " |      start_params=None,\n",
      " |      profile_scale=False,\n",
      " |      refit=False,\n",
      " |      **kwargs\n",
      " |  )\n",
      " |      Return a regularized fit to a linear regression model.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str\n",
      " |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      " |      alpha : scalar or array_like\n",
      " |          The penalty weight.  If a scalar, the same penalty weight\n",
      " |          applies to all variables in the model.  If a vector, it\n",
      " |          must have the same length as `params`, and contains a\n",
      " |          penalty weight for each coefficient.\n",
      " |      L1_wt : scalar\n",
      " |          The fraction of the penalty given to the L1 penalty term.\n",
      " |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      " |          ridge fit, if 1 it is a lasso fit.\n",
      " |      start_params : array_like\n",
      " |          Starting values for ``params``.\n",
      " |      profile_scale : bool\n",
      " |          If True the penalized fit is computed using the profile\n",
      " |          (concentrated) log-likelihood for the Gaussian model.\n",
      " |          Otherwise the fit uses the residual sum of squares.\n",
      " |      refit : bool\n",
      " |          If True, the model is refit using only the variables that\n",
      " |          have non-zero coefficients in the regularized fit.  The\n",
      " |          refitted model is not regularized.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      statsmodels.base.elastic_net.RegularizedResults\n",
      " |          The regularized results.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The elastic net uses a combination of L1 and L2 penalties.\n",
      " |      The implementation closely follows the glmnet package in R.\n",
      " |\n",
      " |      The function that is minimized is:\n",
      " |\n",
      " |      .. math::\n",
      " |\n",
      " |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      " |\n",
      " |      where RSS is the usual regression sum of squares, n is the\n",
      " |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      " |      norms.\n",
      " |\n",
      " |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      " |      exog data.\n",
      " |\n",
      " |      Post-estimation results are based on the same data used to\n",
      " |      select variables, hence may be subject to overfitting biases.\n",
      " |\n",
      " |      The elastic_net method uses the following keyword arguments:\n",
      " |\n",
      " |      maxiter : int\n",
      " |          Maximum number of iterations\n",
      " |      cnvrg_tol : float\n",
      " |          Convergence threshold for line searches\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |\n",
      " |      The square root lasso approach is a variation of the Lasso\n",
      " |      that is largely self-tuning (the optimal tuning parameter\n",
      " |      does not depend on the standard deviation of the regression\n",
      " |      errors).  If the errors are Gaussian, the tuning parameter\n",
      " |      can be taken to be\n",
      " |\n",
      " |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      " |\n",
      " |      where n is the sample size and p is the number of predictors.\n",
      " |\n",
      " |      The square root lasso uses the following keyword arguments:\n",
      " |\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |\n",
      " |      The cvxopt module is required to estimate model using the square root\n",
      " |      lasso.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      " |         generalized linear models via coordinate descent.  Journal of\n",
      " |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      " |\n",
      " |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      " |         pivotal recovery of sparse signals via conic programming.\n",
      " |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      " |\n",
      " |  hessian_factor(self, params, scale=None, observed=True)\n",
      " |      Compute the weights for calculating the Hessian.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameter at which Hessian is evaluated.\n",
      " |      scale : None or float\n",
      " |          If scale is None, then the default scale will be calculated.\n",
      " |          Default scale is defined by `self.scaletype` and set in fit.\n",
      " |          If scale is not None, then it is used as a fixed scale.\n",
      " |      observed : bool\n",
      " |          If True, then the observed Hessian is returned. If false then the\n",
      " |          expected information matrix is returned.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          A 1d weight vector used in the calculation of the Hessian.\n",
      " |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      " |\n",
      " |  loglike(self, params)\n",
      " |      Compute the value of the gaussian log-likelihood function at params.\n",
      " |\n",
      " |      Given the whitened design matrix, the log-likelihood is evaluated\n",
      " |      at the parameter vector `params` for the dependent variable `Y`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameter estimates.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The value of the log-likelihood function for a WLS Model.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. math:: -\\frac{n}{2}\\log SSR\n",
      " |                -\\frac{n}{2}\\left(1+\\log\\left(\\frac{2\\pi}{n}\\right)\\right)\n",
      " |                +\\frac{1}{2}\\log\\left(\\left|W\\right|\\right)\n",
      " |\n",
      " |      where :math:`W` is a diagonal weight matrix,\n",
      " |      :math:`\\left|W\\right|` is its determinant, and\n",
      " |      :math:`SSR=\\left(Y-\\hat{Y}\\right)^\\prime W \\left(Y-\\hat{Y}\\right)` is\n",
      " |      the sum of the squared weighted residuals.\n",
      " |\n",
      " |  whiten(self, x)\n",
      " |      Whitener for WLS model, multiplies each column by sqrt(self.weights).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          Data to be whitened.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          The whitened values sqrt(weights)*X.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RegressionModel:\n",
      " |\n",
      " |  fit(\n",
      " |      self,\n",
      " |      method: \"Literal['pinv', 'qr']\" = 'pinv',\n",
      " |      cov_type: \"Literal['nonrobust', 'fixed scale', 'HC0', 'HC1', 'HC2', 'HC3', 'HAC', 'hac-panel', 'hac-groupsum', 'cluster']\" = 'nonrobust',\n",
      " |      cov_kwds=None,\n",
      " |      use_t: 'bool | None' = None,\n",
      " |      **kwargs\n",
      " |  )\n",
      " |      Full fit of the model.\n",
      " |\n",
      " |      The results include an estimate of covariance matrix, (whitened)\n",
      " |      residuals and an estimate of scale.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, optional\n",
      " |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      " |          to solve the least squares problem. \"qr\" uses the QR\n",
      " |          factorization.\n",
      " |      cov_type : str, optional\n",
      " |          See `regression.linear_model.RegressionResults` for a description\n",
      " |          of the available covariance estimators.\n",
      " |      cov_kwds : list or None, optional\n",
      " |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      " |          description required keywords for alternative covariance\n",
      " |          estimators.\n",
      " |      use_t : bool, optional\n",
      " |          Flag indicating to use the Student's t distribution when computing\n",
      " |          p-values.  Default behavior depends on cov_type. See\n",
      " |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      " |          implementation details.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      RegressionResults\n",
      " |          The model estimation results.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      RegressionResults\n",
      " |          The results container.\n",
      " |      RegressionResults.get_robustcov_results\n",
      " |          A method to change the covariance estimator used when fitting the\n",
      " |          model.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      " |      to solve the least squares minimization.\n",
      " |\n",
      " |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      " |      Construct a random number generator for the predictive distribution.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The model parameters (regression coefficients).\n",
      " |      scale : scalar\n",
      " |          The variance parameter.\n",
      " |      exog : array_like\n",
      " |          The predictor variable matrix.\n",
      " |      dist_class : class\n",
      " |          A random number generator class.  Must take 'loc' and 'scale'\n",
      " |          as arguments and return a random number generator implementing\n",
      " |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      gen\n",
      " |          Frozen random number generator object with mean and variance\n",
      " |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      " |          to generate random values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      " |      the returned random number generator must be called with\n",
      " |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      " |      the data set used to fit the model.  If any other value is\n",
      " |      used for ``n``, misleading results will be produced.\n",
      " |\n",
      " |  initialize(self)\n",
      " |      Initialize model components.\n",
      " |\n",
      " |  predict(self, params, exog=None)\n",
      " |      Return linear predicted values from a design matrix.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Parameters of a linear model.\n",
      " |      exog : array_like, optional\n",
      " |          Design / exogenous data. Model exog is used if None.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          An array of fitted values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the model has not yet been fit, params is not optional.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RegressionModel:\n",
      " |\n",
      " |  df_model\n",
      " |      The model degree of freedom.\n",
      " |\n",
      " |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      " |      constant is included.\n",
      " |\n",
      " |  df_resid\n",
      " |      The residual degree of freedom.\n",
      " |\n",
      " |      The dof is defined as the number of observations minus the rank of\n",
      " |      the regressor matrix.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |\n",
      " |  hessian(self, params)\n",
      " |      The Hessian matrix of the model.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameters to use when evaluating the Hessian.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The hessian evaluated at the parameters.\n",
      " |\n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model.\n",
      " |\n",
      " |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters.\n",
      " |\n",
      " |  score(self, params)\n",
      " |      Score vector of model.\n",
      " |\n",
      " |      The gradient of logL with respect to each parameter.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameters to use when evaluating the Hessian.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The score vector evaluated at the parameters.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs)\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model.\n",
      " |      data : array_like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array_like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`.\n",
      " |      drop_cols : array_like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      *args\n",
      " |          Additional positional argument that are passed to the model.\n",
      " |      **kwargs\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      model\n",
      " |          The model instance.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  endog_names\n",
      " |      Names of endogenous variables.\n",
      " |\n",
      " |  exog_names\n",
      " |      Names of exogenous variables.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "help(sm.WLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The statsmodels way\n",
    "import statsmodels.api as sm\n",
    "X = logv\n",
    "#fit for a constant too\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# do the fit.  We could have done this in two lines as:\n",
    "#model = sm.WLS(mu, X,weights=weight)\n",
    "#result = model.fit()\n",
    "\n",
    "results = sm.WLS(mu, X, weights=weight).fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now, examine the results using the below code.__  `statsmodels` provides all the info you ever wanted and more.  This is documented at https://www.statsmodels.org/0.8.0/generated/statsmodels.regression.linear_model.RegressionResults.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mu</td>        <th>  R-squared:         </th> <td>   0.970</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.969</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5161.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 14 Apr 2025</td> <th>  Prob (F-statistic):</th> <td>9.05e-125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:46:46</td>     <th>  Log-Likelihood:    </th> <td>  50.730</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   164</td>      <th>  AIC:               </th> <td>  -97.46</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   162</td>      <th>  BIC:               </th> <td>  -91.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   15.7770</td> <td>    0.280</td> <td>   56.441</td> <td> 0.000</td> <td>   15.225</td> <td>   16.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cz</th>    <td>    5.0540</td> <td>    0.070</td> <td>   71.838</td> <td> 0.000</td> <td>    4.915</td> <td>    5.193</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.919</td> <th>  Durbin-Watson:     </th> <td>   2.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.085</td> <th>  Jarque-Bera (JB):  </th> <td>   5.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.261</td> <th>  Prob(JB):          </th> <td>  0.0806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.682</td> <th>  Cond. No.          </th> <td>    86.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        mu        & \\textbf{  R-squared:         } &     0.970   \\\\\n",
       "\\textbf{Model:}            &       WLS        & \\textbf{  Adj. R-squared:    } &     0.969   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     5161.   \\\\\n",
       "\\textbf{Date:}             & Mon, 14 Apr 2025 & \\textbf{  Prob (F-statistic):} & 9.05e-125   \\\\\n",
       "\\textbf{Time:}             &     12:46:46     & \\textbf{  Log-Likelihood:    } &    50.730   \\\\\n",
       "\\textbf{No. Observations:} &         164      & \\textbf{  AIC:               } &    -97.46   \\\\\n",
       "\\textbf{Df Residuals:}     &         162      & \\textbf{  BIC:               } &    -91.26   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      15.7770  &        0.280     &    56.441  &         0.000        &       15.225    &       16.329     \\\\\n",
       "\\textbf{cz}    &       5.0540  &        0.070     &    71.838  &         0.000        &        4.915    &        5.193     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  4.919 & \\textbf{  Durbin-Watson:     } &    2.223  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.085 & \\textbf{  Jarque-Bera (JB):  } &    5.038  \\\\\n",
       "\\textbf{Skew:}          &  0.261 & \\textbf{  Prob(JB):          } &   0.0806  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.682 & \\textbf{  Cond. No.          } &     86.0  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{WLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     mu   R-squared:                       0.970\n",
       "Model:                            WLS   Adj. R-squared:                  0.969\n",
       "Method:                 Least Squares   F-statistic:                     5161.\n",
       "Date:                Mon, 14 Apr 2025   Prob (F-statistic):          9.05e-125\n",
       "Time:                        12:46:46   Log-Likelihood:                 50.730\n",
       "No. Observations:                 164   AIC:                            -97.46\n",
       "Df Residuals:                     162   BIC:                            -91.26\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         15.7770      0.280     56.441      0.000      15.225      16.329\n",
       "cz             5.0540      0.070     71.838      0.000       4.915       5.193\n",
       "==============================================================================\n",
       "Omnibus:                        4.919   Durbin-Watson:                   2.223\n",
       "Prob(Omnibus):                  0.085   Jarque-Bera (JB):                5.038\n",
       "Skew:                           0.261   Prob(JB):                       0.0806\n",
       "Kurtosis:                       3.682   Cond. No.                         86.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = results.params[1]\n",
    "intercept = results.params[0]\n",
    "\n",
    "\n",
    "# statsmodels provides multiple estimates of the standard error\n",
    "err_slope=results.HC0_se[1]\n",
    "err_intercept=results.HC0_se[0]\n",
    "\n",
    "h0err = (10**(-0.2*(intercept-err_intercept) )-np.log10(1E-5) - \\\n",
    "    10**(-0.2*(intercept+err_intercept) )-np.log10(1E-5) )/2.\n",
    "\n",
    "if 1:\n",
    "    print(f'slope: {slope:.3f} +/- {err_slope:.3f}')\n",
    "    print(f'intercept: {intercept:.3f} +/- {np.sqrt(covar[1,1]):.3f}')\n",
    "    print(f'H0: {(10**(-0.2*intercept-np.log10(1E-5))):.2f} km/sec/Mpc +/- {h0err:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying robust fitting\n",
    "\n",
    "__Look at the help on sm.RLM using the below code box.__  Here M denotes the function used to penalize outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RLM in module statsmodels.robust.robust_linear_model:\n",
      "\n",
      "class RLM(statsmodels.base.model.LikelihoodModel)\n",
      " |  RLM(endog, exog, M=None, missing='none', **kwargs)\n",
      " |\n",
      " |  Robust Linear Model\n",
      " |\n",
      " |  Estimate a robust linear model via iteratively reweighted least squares\n",
      " |  given a robust criterion estimator.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array_like\n",
      " |      A 1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array_like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  M : statsmodels.robust.norms.RobustNorm, optional\n",
      " |      The robust criterion function for downweighting outliers.\n",
      " |      The current options are LeastSquares, HuberT, RamsayE, AndrewWave,\n",
      " |      TrimmedMean, Hampel, and TukeyBiweight.  The default is HuberT().\n",
      " |      See statsmodels.robust.norms for more information.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none'.\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |\n",
      " |  df_model : float\n",
      " |      The degrees of freedom of the model.  The number of regressors p less\n",
      " |      one for the intercept.  Note that the reported model degrees\n",
      " |      of freedom does not count the intercept as a regressor, though\n",
      " |      the model is assumed to have an intercept.\n",
      " |  df_resid : float\n",
      " |      The residual degrees of freedom.  The number of observations n\n",
      " |      less the number of regressors p.  Note that here p does include\n",
      " |      the intercept as using a degree of freedom.\n",
      " |  endog : ndarray\n",
      " |      See above.  Note that endog is a reference to the data so that if\n",
      " |      data is already an array and it is changed, then `endog` changes\n",
      " |      as well.\n",
      " |  exog : ndarray\n",
      " |      See above.  Note that endog is a reference to the data so that if\n",
      " |      data is already an array and it is changed, then `endog` changes\n",
      " |      as well.\n",
      " |  M : statsmodels.robust.norms.RobustNorm\n",
      " |       See above.  Robust estimator instance instantiated.\n",
      " |  nobs : float\n",
      " |      The number of observations n\n",
      " |  pinv_wexog : ndarray\n",
      " |      The pseudoinverse of the design / exogenous data array.  Note that\n",
      " |      RLM has no whiten method, so this is just the pseudo inverse of the\n",
      " |      design.\n",
      " |  normalized_cov_params : ndarray\n",
      " |      The p x p normalized covariance of the design / exogenous data.\n",
      " |      This is approximately equal to (X.T X)^(-1)\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import statsmodels.api as sm\n",
      " |  >>> data = sm.datasets.stackloss.load()\n",
      " |  >>> data.exog = sm.add_constant(data.exog)\n",
      " |  >>> rlm_model = sm.RLM(data.endog, data.exog,                            M=sm.robust.norms.HuberT())\n",
      " |\n",
      " |  >>> rlm_results = rlm_model.fit()\n",
      " |  >>> rlm_results.params\n",
      " |  array([  0.82938433,   0.92606597,  -0.12784672, -41.02649835])\n",
      " |  >>> rlm_results.bse\n",
      " |  array([ 0.11100521,  0.30293016,  0.12864961,  9.79189854])\n",
      " |  >>> rlm_results_HC2 = rlm_model.fit(cov=\"H2\")\n",
      " |  >>> rlm_results_HC2.params\n",
      " |  array([  0.82938433,   0.92606597,  -0.12784672, -41.02649835])\n",
      " |  >>> rlm_results_HC2.bse\n",
      " |  array([ 0.11945975,  0.32235497,  0.11796313,  9.08950419])\n",
      " |  >>> mod = sm.RLM(data.endog, data.exog, M=sm.robust.norms.Hampel())\n",
      " |  >>> rlm_hamp_hub = mod.fit(scale_est=sm.robust.scale.HuberScale())\n",
      " |  >>> rlm_hamp_hub.params\n",
      " |  array([  0.73175452,   1.25082038,  -0.14794399, -40.27122257])\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      RLM\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, endog, exog, M=None, missing='none', **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  deviance(self, tmp_results)\n",
      " |      Returns the (unnormalized) log-likelihood from the M estimator.\n",
      " |\n",
      " |  fit(\n",
      " |      self,\n",
      " |      maxiter=50,\n",
      " |      tol=1e-08,\n",
      " |      scale_est='mad',\n",
      " |      init=None,\n",
      " |      cov='H1',\n",
      " |      update_scale=True,\n",
      " |      conv='dev',\n",
      " |      start_params=None\n",
      " |  )\n",
      " |      Fits the model using iteratively reweighted least squares.\n",
      " |\n",
      " |      The IRLS routine runs until the specified objective converges to `tol`\n",
      " |      or `maxiter` has been reached.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      conv : str\n",
      " |          Indicates the convergence criteria.\n",
      " |          Available options are \"coefs\" (the coefficients), \"weights\" (the\n",
      " |          weights in the iteration), \"sresid\" (the standardized residuals),\n",
      " |          and \"dev\" (the un-normalized log-likelihood for the M\n",
      " |          estimator).  The default is \"dev\".\n",
      " |      cov : str, optional\n",
      " |          'H1', 'H2', or 'H3'\n",
      " |          Indicates how the covariance matrix is estimated.  Default is 'H1'.\n",
      " |          See rlm.RLMResults for more information.\n",
      " |      init : str\n",
      " |          Specifies method for the initial estimates of the parameters.\n",
      " |          Default is None, which means that the least squares estimate\n",
      " |          is used.  Currently it is the only available choice.\n",
      " |      maxiter : int\n",
      " |          The maximum number of iterations to try. Default is 50.\n",
      " |      scale_est : str or HuberScale()\n",
      " |          'mad' or HuberScale()\n",
      " |          Indicates the estimate to use for scaling the weights in the IRLS.\n",
      " |          The default is 'mad' (median absolute deviation.  Other options are\n",
      " |          'HuberScale' for Huber's proposal 2. Huber's proposal 2 has\n",
      " |          optional keyword arguments d, tol, and maxiter for specifying the\n",
      " |          tuning constant, the convergence tolerance, and the maximum number\n",
      " |          of iterations. See statsmodels.robust.scale for more information.\n",
      " |      tol : float\n",
      " |          The convergence tolerance of the estimate.  Default is 1e-8.\n",
      " |      update_scale : Bool\n",
      " |          If `update_scale` is False then the scale estimate for the\n",
      " |          weights is held constant over the iteration.  Otherwise, it\n",
      " |          is updated for each fit in the iteration.  Default is True.\n",
      " |      start_params : array_like, optional\n",
      " |          Initial guess of the solution of the optimizer. If not provided,\n",
      " |          the initial parameters are computed using OLS.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      results : statsmodels.rlm.RLMresults\n",
      " |          Results instance\n",
      " |\n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model.\n",
      " |\n",
      " |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters.\n",
      " |\n",
      " |  loglike(self, params)\n",
      " |      Log-likelihood of model.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters used to compute the log-likelihood.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Must be overridden by subclasses.\n",
      " |\n",
      " |  predict(self, params, exog=None)\n",
      " |      Return linear predicted values from a design matrix.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Parameters of a linear model\n",
      " |      exog : array_like, optional.\n",
      " |          Design / exogenous data. Model exog is used if None.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      An array of fitted values\n",
      " |\n",
      " |  score(self, params)\n",
      " |      Score vector of model.\n",
      " |\n",
      " |      The gradient of logL with respect to each parameter.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameters to use when evaluating the Hessian.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The score vector evaluated at the parameters.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |\n",
      " |  hessian(self, params)\n",
      " |      The Hessian matrix of the model.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameters to use when evaluating the Hessian.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The hessian evaluated at the parameters.\n",
      " |\n",
      " |  initialize(self)\n",
      " |      Initialize (possibly re-initialize) a Model instance.\n",
      " |\n",
      " |      For example, if the the design matrix of a linear model changes then\n",
      " |      initialized can be used to recompute values using the modified design\n",
      " |      matrix.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs)\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model.\n",
      " |      data : array_like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array_like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`.\n",
      " |      drop_cols : array_like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      *args\n",
      " |          Additional positional argument that are passed to the model.\n",
      " |      **kwargs\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      model\n",
      " |          The model instance.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  endog_names\n",
      " |      Names of endogenous variables.\n",
      " |\n",
      " |  exog_names\n",
      " |      Names of exogenous variables.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sm.RLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    15.630385\n",
      "cz        5.091046\n",
      "dtype: float64\n",
      "Huber t slope, H0: 5.0910, 74.8037\n",
      "\n",
      "Trimmed mean slope, H0: 5.1211, 79.0722\n",
      "\n",
      "Biweight slope, H0: 5.0930, 75.1726\n"
     ]
    }
   ],
   "source": [
    "# use a t-distribution based deweighting\n",
    "rlm_model = sm.RLM(mu, X, M=sm.robust.norms.HuberT())\n",
    "rlm_results = rlm_model.fit()\n",
    "print(rlm_results.params)\n",
    "intercept = (rlm_results.params.iloc[0])\n",
    "slope = (rlm_results.params.iloc[1])\n",
    "print(f'Huber t slope, H0: {slope:.4f}, {10**(-0.2*intercept-np.log10(1E-5)):.4f}')\n",
    "print()\n",
    "\n",
    "rlm_model = sm.RLM(mu, X, M=sm.robust.norms.TrimmedMean())\n",
    "rlm_results_tm = rlm_model.fit()\n",
    "#print(rlm_results_tm.params)\n",
    "intercept = (rlm_results_tm.params.iloc[0])\n",
    "slope = (rlm_results_tm.params.iloc[1])\n",
    "print(f'Trimmed mean slope, H0: {slope:.4f}, {10**(-0.2*intercept-np.log10(1E-5)):.4f}')\n",
    "\n",
    "print()\n",
    "rlm_model = sm.RLM(mu, X, M=sm.robust.norms.TukeyBiweight())\n",
    "rlm_results_tw = rlm_model.fit()  # Updated variable name for TukeyBiweight results\n",
    "#print(rlm_results_tw.params)\n",
    "intercept = (rlm_results_tw.params.iloc[0])  # Updated to use rlm_results_tw\n",
    "slope = (rlm_results_tw.params.iloc[1])  # Updated to use rlm_results_tw\n",
    "\n",
    "print(f'Biweight slope, H0: {slope:.4f}, {10**(-0.2*intercept-np.log10(1E-5)):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Robust linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>mu</td>        <th>  No. Observations:  </th> <td>   164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>RLM</td>       <th>  Df Residuals:      </th> <td>   162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Df Model:          </th> <td>     1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Norm:</th>             <td>TukeyBiweight</td>  <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Scale Est.:</th>            <td>mad</td>       <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov Type:</th>              <td>H1</td>        <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 14 Apr 2025</td> <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>12:57:23</td>     <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>        <td>15</td>        <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   15.6197</td> <td>    0.266</td> <td>   58.688</td> <td> 0.000</td> <td>   15.098</td> <td>   16.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cz</th>    <td>    5.0930</td> <td>    0.068</td> <td>   75.377</td> <td> 0.000</td> <td>    4.961</td> <td>    5.225</td>\n",
       "</tr>\n",
       "</table><br/><br/>If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore ."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}  &        mu        & \\textbf{  No. Observations:  } &      164    \\\\\n",
       "\\textbf{Model:}          &       RLM        & \\textbf{  Df Residuals:      } &      162    \\\\\n",
       "\\textbf{Method:}         &       IRLS       & \\textbf{  Df Model:          } &        1    \\\\\n",
       "\\textbf{Norm:}           &  TukeyBiweight   & \\textbf{                     } &             \\\\\n",
       "\\textbf{Scale Est.:}     &       mad        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Cov Type:}       &        H1        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Date:}           & Mon, 14 Apr 2025 & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}           &     12:57:23     & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Iterations:} &        15        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      15.6197  &        0.266     &    58.688  &         0.000        &       15.098    &       16.141     \\\\\n",
       "\\textbf{cz}    &       5.0930  &        0.068     &    75.377  &         0.000        &        4.961    &        5.225     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Robust linear Model Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore ."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                    Robust linear Model Regression Results                    \n",
       "==============================================================================\n",
       "Dep. Variable:                     mu   No. Observations:                  164\n",
       "Model:                            RLM   Df Residuals:                      162\n",
       "Method:                          IRLS   Df Model:                            1\n",
       "Norm:                   TukeyBiweight                                         \n",
       "Scale Est.:                       mad                                         \n",
       "Cov Type:                          H1                                         \n",
       "Date:                Mon, 14 Apr 2025                                         \n",
       "Time:                        12:57:23                                         \n",
       "No. Iterations:                    15                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         15.6197      0.266     58.688      0.000      15.098      16.141\n",
       "cz             5.0930      0.068     75.377      0.000       4.961       5.225\n",
       "==============================================================================\n",
       "\n",
       "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rlm_results.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Robust linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>mu</td>        <th>  No. Observations:  </th> <td>   164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>RLM</td>       <th>  Df Residuals:      </th> <td>   162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Df Model:          </th> <td>     1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Norm:</th>              <td>TrimmedMean</td>   <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Scale Est.:</th>            <td>mad</td>       <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov Type:</th>              <td>H1</td>        <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 14 Apr 2025</td> <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>12:57:41</td>     <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>4</td>        <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   15.5099</td> <td>    0.212</td> <td>   73.125</td> <td> 0.000</td> <td>   15.094</td> <td>   15.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cz</th>    <td>    5.1211</td> <td>    0.054</td> <td>   95.108</td> <td> 0.000</td> <td>    5.016</td> <td>    5.227</td>\n",
       "</tr>\n",
       "</table><br/><br/>If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore ."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}  &        mu        & \\textbf{  No. Observations:  } &      164    \\\\\n",
       "\\textbf{Model:}          &       RLM        & \\textbf{  Df Residuals:      } &      162    \\\\\n",
       "\\textbf{Method:}         &       IRLS       & \\textbf{  Df Model:          } &        1    \\\\\n",
       "\\textbf{Norm:}           &   TrimmedMean    & \\textbf{                     } &             \\\\\n",
       "\\textbf{Scale Est.:}     &       mad        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Cov Type:}       &        H1        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Date:}           & Mon, 14 Apr 2025 & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}           &     12:57:41     & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Iterations:} &        4         & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      15.5099  &        0.212     &    73.125  &         0.000        &       15.094    &       15.926     \\\\\n",
       "\\textbf{cz}    &       5.1211  &        0.054     &    95.108  &         0.000        &        5.016    &        5.227     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Robust linear Model Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore ."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                    Robust linear Model Regression Results                    \n",
       "==============================================================================\n",
       "Dep. Variable:                     mu   No. Observations:                  164\n",
       "Model:                            RLM   Df Residuals:                      162\n",
       "Method:                          IRLS   Df Model:                            1\n",
       "Norm:                     TrimmedMean                                         \n",
       "Scale Est.:                       mad                                         \n",
       "Cov Type:                          H1                                         \n",
       "Date:                Mon, 14 Apr 2025                                         \n",
       "Time:                        12:57:41                                         \n",
       "No. Iterations:                     4                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         15.5099      0.212     73.125      0.000      15.094      15.926\n",
       "cz             5.1211      0.054     95.108      0.000       5.016       5.227\n",
       "==============================================================================\n",
       "\n",
       "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlm_results_tm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Robust linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>mu</td>        <th>  No. Observations:  </th> <td>   164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>RLM</td>       <th>  Df Residuals:      </th> <td>   162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Df Model:          </th> <td>     1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Norm:</th>             <td>TukeyBiweight</td>  <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Scale Est.:</th>            <td>mad</td>       <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov Type:</th>              <td>H1</td>        <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 14 Apr 2025</td> <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>12:57:47</td>     <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>        <td>15</td>        <th>                     </th>    <td> </td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   15.6197</td> <td>    0.266</td> <td>   58.688</td> <td> 0.000</td> <td>   15.098</td> <td>   16.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cz</th>    <td>    5.0930</td> <td>    0.068</td> <td>   75.377</td> <td> 0.000</td> <td>    4.961</td> <td>    5.225</td>\n",
       "</tr>\n",
       "</table><br/><br/>If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore ."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}  &        mu        & \\textbf{  No. Observations:  } &      164    \\\\\n",
       "\\textbf{Model:}          &       RLM        & \\textbf{  Df Residuals:      } &      162    \\\\\n",
       "\\textbf{Method:}         &       IRLS       & \\textbf{  Df Model:          } &        1    \\\\\n",
       "\\textbf{Norm:}           &  TukeyBiweight   & \\textbf{                     } &             \\\\\n",
       "\\textbf{Scale Est.:}     &       mad        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Cov Type:}       &        H1        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Date:}           & Mon, 14 Apr 2025 & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}           &     12:57:47     & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Iterations:} &        15        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      15.6197  &        0.266     &    58.688  &         0.000        &       15.098    &       16.141     \\\\\n",
       "\\textbf{cz}    &       5.0930  &        0.068     &    75.377  &         0.000        &        4.961    &        5.225     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Robust linear Model Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore ."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                    Robust linear Model Regression Results                    \n",
       "==============================================================================\n",
       "Dep. Variable:                     mu   No. Observations:                  164\n",
       "Model:                            RLM   Df Residuals:                      162\n",
       "Method:                          IRLS   Df Model:                            1\n",
       "Norm:                   TukeyBiweight                                         \n",
       "Scale Est.:                       mad                                         \n",
       "Cov Type:                          H1                                         \n",
       "Date:                Mon, 14 Apr 2025                                         \n",
       "Time:                        12:57:47                                         \n",
       "No. Iterations:                    15                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         15.6197      0.266     58.688      0.000      15.098      16.141\n",
       "cz             5.0930      0.068     75.377      0.000       4.961       5.225\n",
       "==============================================================================\n",
       "\n",
       "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlm_results_tw.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
